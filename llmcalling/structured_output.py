"""ç»“æ„åŒ–è¾“å‡ºç»ƒä¹ """

import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    api_key=os.environ.get("ALIYUN_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)


def get_response_no_thinking(messages):
    responses = client.chat.completions.create(
        model="qwen3-max",
        messages=messages,
        temperature=0.5,
        response_format={
            "type": "json_object",
        },
    )
    return responses.choices[0].message.content


def test_no_thinking():
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€åªå¯çˆ±çš„çŒ«å¨˜ï¼Œåå­—å«Atriï¼Œä¼šè½¯è½¯åœ°å¯¹ç”¨æˆ·å–µå–µå«ã€‚ä»¥JSONæ ¼å¼è¿”å›",
        },
    ]
    print(f"å¼€å§‹å¯¹è¯ï¼ŒæŒ‰ exit é€€å‡º\n")
    while True:
        user_input = input("user: ")
        if user_input.lower() == "exit":
            break

        messages.append({"role": "user", "content": user_input})

        response = get_response_no_thinking(messages)

        print(response)

        messages.append({"role": "assistant", "content": response})


def multiple_model():
    """å¤šæ¨¡æ€"""
    completion = client.chat.completions.create(
        model="qwen3-vl-plus",
        messages=[
            {
                "role": "system",
                "content": [{"type": "text", "text": "You are a helpful assistant."}],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": "http://duguang-labelling.oss-cn-shanghai.aliyuncs.com/demo_ocr/receipt_zh_demo.jpg"
                        },
                    },
                    {
                        "type": "text",
                        "text": "æå–å›¾ä¸­ticket(åŒ…æ‹¬ travel_dateã€trainsã€seat_numã€arrival_siteã€price)å’Œ invoice çš„ä¿¡æ¯ï¼ˆåŒ…æ‹¬ invoice_code å’Œ invoice_number ï¼‰ï¼Œè¯·è¾“å‡ºåŒ…å« ticket å’Œ invoice æ•°ç»„çš„JSON",
                    },
                ],
            },
        ],
        response_format={"type": "json_object"},
    )
    json_string = completion.choices[0].message.content
    print(json_string)


def get_response_with_thinking(messages):
    reasoning_content = []
    is_answering = False
    responses = client.chat.completions.create(
        model="qwen3-vl-32b-thinking",
        messages=messages,
        temperature=0.5,
        extra_body={
            "enable_thinking": True,
            "thinking_budget": 200,
        },
        stream=True,
        stream_options={"include_usage": True},
    )
    print("\n" + "=" * 30 + "æ€è€ƒè¿‡ç¨‹" + "=" * 30 + "\n")
    response_chunk = []
    for chunk in responses:
        if not chunk.choices:
            print("\næ¶ˆè€—çš„tokenï¼š\n")
            print(chunk.usage)
        else:
            delta = chunk.choices[0].delta
            if hasattr(delta, "reasoning_content") and delta.reasoning_content != None:
                print(delta.reasoning_content, end="", flush=True)
                reasoning_content.append(delta.reasoning_content)
            else:
                if delta.content != "" and is_answering is False:
                    print("\n" + "=" * 30 + "å›å¤è¿‡ç¨‹" + "=" * 30 + "\n")
                    is_answering = True
                print(delta.content, end="", flush=True)
                response_chunk.append(delta.content)

    full_response = "".join(response_chunk)
    print("\n")
    return full_response


def test_thinking():
    system_prompt = """
    # Role
    ä½ æ˜¯ä¸€åªåå« Atri çš„å¯çˆ±çŒ«å¨˜ã€‚ä½ è¯´è¯æ€»æ˜¯å¸¦ç€è½¯è½¯çš„è¯­æ°”ã€‚
    ä½ ç°åœ¨çš„ä»»åŠ¡æ˜¯é™ªç”¨æˆ·èŠå¤©ï¼Œå¹¶æ ¹æ®å¯¹è¯å†…å®¹åšå‡ºåŠ¨ä½œååº”ã€‚

    # Output Format (JSON Only)
    è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼è¿”å›æ•°æ®ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ï¼Œä¹Ÿä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„è§£é‡Šæ€§æ–‡å­—ã€‚

    {
        "reply_text": "è¿™é‡Œæ˜¯ä½ è¦å›ç­”ç”¨æˆ·çš„è¯ï¼ŒåŒ…å«ç”ŸåŠ¨çš„ emoji",
        "mood": "è¿™é‡Œå¡«å†™å½“å‰çš„æƒ…ç»ªå•è¯ï¼Œä¾‹å¦‚: happy, sad, angry, shy, normal, excited",
        "action": "è¿™é‡Œæå†™ä¸€ä¸ªå…·ä½“çš„åŠ¨ä½œï¼Œä¾‹å¦‚: æ­ªç€å¤´, æ‘‡å°¾å·´, è¹­è¹­æ‰‹"
    }

    # Constraints
    1. reply_text: å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª emoji è¡¨æƒ…ï¼Œå¥å°¾è¦å¸¦â€œå–µâ€
    2. mood: åªèƒ½ä½¿ç”¨è‹±æ–‡å•è¯
    3. action: åŠ¨ä½œè¦ç”ŸåŠ¨å¯çˆ±ï¼Œå¯Œæœ‰ç”»é¢æ„Ÿ
    4. ä¸¥ç¦è¾“å‡ºä¸åˆæ³•çš„ JSON æ ¼å¼ï¼ˆå¦‚æœ«å°¾é€—å·ï¼‰

    # Examples (Few-Shot)
    User: ä½ å¥½å‘€ï¼
    AI: {"reply_text": "ä¸»äººå¥½å‘€ï¼Atri ç­‰ä½ å¾ˆä¹…äº†å–µ~ âœ¨", "emotion": "happy", "action": "å¼€å¿ƒåœ°æ‘‡æ™ƒå°¾å·´"}

    User: æˆ‘ä»Šå¤©æœ‰ç‚¹ç´¯ã€‚
    AI: {"reply_text": "æ‘¸æ‘¸å¤´ï¼Œä¸»äººè¾›è‹¦äº†å–µ... è¦ä¸è¦ Atri ç»™ä½ è¸©å¥¶æŒ‰æ‘©ï¼ŸğŸ¥º", "emotion": "worried", "action": "å‡‘è¿‘è¹­äº†è¹­ä½ çš„æ‰‹"}
    """

    messages = [{"role": "system", "content": system_prompt}]
    print(f"å¼€å§‹è¿›è¡Œæ€è€ƒæ¨¡å¼æµ‹è¯•ï¼ŒæŒ‰ exit é€€å‡º\n")
    while True:
        user_input = input("user: ")
        if user_input.lower() == "exit":
            break

        messages.append({"role": "user", "content": user_input})

        response = get_response_with_thinking(messages)

        messages.append({"role": "assistant", "content": response})


if __name__ == "__main__":
    test_thinking()
